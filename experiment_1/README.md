# ğŸ¤– MCP-Powered Math Agent

A blazing-fast Python agent that connects to a custom **Math server** via [LangChain MCP](https://github.com/langchain-ai/langchain/tree/main/libs/langchain_mcp_adapters), uses [`ChatOllama`](https://github.com/langchain-ai/langchain-ollama), and executes instructions like:

> â€œWhatâ€™s (10 + 34 + 200) Ã— 12 Ã— 30?â€

ğŸŒ Powered by local models like `qwen3` via [Ollama](https://ollama.com), and built with modern AI orchestration tools like **LangGraph**.

---

## ğŸ“¦ Features

âœ… Connects to a custom math server using `stdio`  
âœ… Uses MCP tools to add and multiply via structured tool calling  
âœ… Interacts with local LLMs using `langchain_ollama`  
âœ… Executes multi-step instructions agentically  
âœ… Built with `asyncio` and `LangGraph` REACT agent

---

## ğŸ—‚ Project Structure

```
mcp-project-1/
â”œâ”€â”€ my_client.py      # Starts the REACT agent and sends a math question
â”œâ”€â”€ my_server.py      # MCP server exposing `add` and `multiply` tools
â”œâ”€â”€ pyproject.toml    # Poetry config with dependencies
â”œâ”€â”€ README.md         # You're reading it!
â””â”€â”€ .gitignore        # Ignored files and folders
```

---

## ğŸš€ Getting Started

### ğŸ§± Prerequisites

- Python **3.12+**
- [Poetry](https://python-poetry.org/) for dependency management
- [Ollama](https://ollama.com) installed and running locally (e.g. with `qwen3` model)

### ğŸ“¥ Installation

```bash
# Clone the repo
git clone https://github.com/yourusername/mcp-project-1.git
cd mcp-project-1

# Install dependencies
poetry install

# Activate the environment
poetry shell
```

---

## ğŸ§ª Running the Agent

Make sure your model (e.g., `qwen3:latest`) is available in Ollama:

```bash
ollama pull qwen3
ollama run qwen3
```

Then run the agent:

```bash
poetry run python my_client.py
```

You'll see output like:

```
The result of (10 + 34 + 200) Ã— 12 Ã— 30 is 87,840
```

---

## ğŸ›  Custom Math Server (MCP)

`my_server.py` defines two tools:

```python
@mcp.tool()
def add(a: int, b: int) -> int: return a + b

@mcp.tool()
def multiply(a: int, b: int) -> int: return a * b
```

Run the server in background (if needed):

```bash
python my_server.py
```

Or let the client spawn it via stdio (as it does now).

---

## ğŸ“š Dependencies

Managed with Poetry via `pyproject.toml`:

- `langchain-mcp-adapters`
- `langgraph`
- `langchain-ollama`
- `asyncio`

---

## ğŸ‘¨â€ğŸ’» Author

Created by **[bibinkunjumon2020](mailto:bibinkunjumon2020@gmail.com)**  
ğŸ”— GitHub: [yourusername](https://github.com/yourusername)

---

## ğŸ§  Powered By

- ğŸ§© [LangGraph](https://github.com/langchain-ai/langgraph)
- ğŸ§  [LangChain](https://www.langchain.com/)
- ğŸ¦™ [Ollama](https://ollama.com)
- âš™ï¸ [LangChain MCP Adapters](https://github.com/langchain-ai/langchain/tree/main/libs/langchain_mcp_adapters)

---

## ğŸ“„ License

MIT â€“ use it, hack it, share it.
